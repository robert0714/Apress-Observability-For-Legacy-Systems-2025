# Custom Models
## Model support
- As of OpenSearch 2.6, OpenSearch supports local text embedding models.

- As of OpenSearch 2.11, OpenSearch supports local sparse encoding models.

- As of OpenSearch 2.12, OpenSearch supports local cross-encoder models.

- As of OpenSearch 2.13, OpenSearch supports local question answering models.

## Preparing a model
For all the models, you must provide a tokenizer JSON file within the model zip file.

For sparse encoding models, make sure your output format is {"output":<sparse_vector>} so that ML Commons can post-process the sparse vector.

If you fine-tune a sparse model on your own dataset, you may also want to use your own sparse tokenizer model. It is preferable to provide your own IDF JSON file in the tokenizer model zip file because this increases query performance when you use the tokenizer model in the query. If the IDF file is not provided, the default weight of each token is set to 1, which may influence sparse neural search performance.

> Open `tokenizer.json` and `IDF.json` files in `data\opensearch-neural-sparse-tokenizer-v1-1.0.0` folder to see example tokens and IDF values for those tokens for [OpenSearch-provided generic IDF from MSMARCO](https://artifacts.opensearch.org/models/ml-models/amazon/neural-sparse/opensearch-neural-sparse-tokenizer-v1/1.0.0/torch_script/opensearch-neural-sparse-tokenizer-v1-1.0.0.zip)

## Model Format
- As of Version 2.5, OpenSearch only supports the TorchScript and ONNX formats.

- You must save the model file as zip before uploading it to OpenSearch. To ensure that ML Commons can upload your model, compress your TorchScript file before uploading. For an example, download a [TorchScript model file](https://github.com/opensearch-project/ml-commons/blob/2.x/ml-algorithms/src/test/resources/org/opensearch/ml/engine/algorithms/text_embedding/all-MiniLM-L6-v2_torchscript_sentence-transformer.zip).
- Additionally, you must calculate a SHA256 checksum for the model zip file that you’ll need to provide when registering the model. For example, on UNIX, use the following command to obtain the checksum:

```bash
shasum -a 256 sentence-transformers_paraphrase-mpnet-base-v2-1.0.0-onnx.zip
```

## Model size
Most deep learning models are more than 100 MB, making it difficult to fit them into a single document. OpenSearch splits the model file into smaller chunks to be stored in a model index. When allocating ML or data nodes for your OpenSearch cluster, make sure you correctly size your ML nodes so that you have enough memory when making ML inferences.

## Prerequisites
To upload a custom model to OpenSearch, you need to prepare it outside of your OpenSearch cluster. You can use a pretrained model, like one from Hugging Face, or train a new model in accordance with your needs

```json
PUT _cluster/settings
{
  "persistent": {
    "plugins": {
      "ml_commons": {
        "allow_registering_model_via_url": "true",
        "only_run_on_ml_node": "false",
        "model_access_control_enabled": "true",
        "native_memory_threshold": "99"
      }
    }
  }
}
```

## Step 1: Register a model group

```json
POST /_plugins/_ml/model_groups/_register
{
  "name": "local_model_group",
  "description": "A model group for local models"
}
```

## Step 2: Register a local model

- The function_name corresponds to the model type. For text embedding models, set this parameter to TEXT_EMBEDDING. 
- For sparse encoding models, set this parameter to SPARSE_ENCODING or SPARSE_TOKENIZE. 
- For cross-encoder models, set this parameter to TEXT_SIMILARITY. 
- For question answering models, set this parameter to QUESTION_ANSWERING. 
  
> In this example, set function_name to TEXT_EMBEDDING because you’re registering a text embedding model.

```json
POST /_plugins/_ml/models/_register
{
  "name": "huggingface/sentence-transformers/msmarco-distilbert-base-tas-b",
  "version": "1.0.1",
  "model_group_id": "wlcnb4kBJ1eYAeTMHlV6",
  "description": "This is a port of the DistilBert TAS-B Model to sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and is optimized for the task of semantic search.",
  "function_name": "TEXT_EMBEDDING",
  "model_format": "TORCH_SCRIPT",
  "model_content_size_in_bytes": 266352827,
  "model_content_hash_value": "acdc81b652b83121f914c5912ae27c0fca8fabf270e6f191ace6979a19830413",
  "model_config": {
    "model_type": "distilbert",
    "embedding_dimension": 768,
    "framework_type": "sentence_transformers",
    "all_config": """{"_name_or_path":"old_models/msmarco-distilbert-base-tas-b/0_Transformer","activation":"gelu","architectures":["DistilBertModel"],"attention_dropout":0.1,"dim":768,"dropout":0.1,"hidden_dim":3072,"initializer_range":0.02,"max_position_embeddings":512,"model_type":"distilbert","n_heads":12,"n_layers":6,"pad_token_id":0,"qa_dropout":0.1,"seq_classif_dropout":0.2,"sinusoidal_pos_embds":false,"tie_weights_":true,"transformers_version":"4.7.0","vocab_size":30522}"""
  },
  "created_time": 1676073973126,
  "url": "https://artifacts.opensearch.org/models/ml-models/huggingface/sentence-transformers/msmarco-distilbert-base-tas-b/1.0.1/torch_script/sentence-transformers_msmarco-distilbert-base-tas-b-1.0.1-torch_script.zip"
}
```